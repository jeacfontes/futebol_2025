{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJwTc/IKD3GZFNIe4d7V0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeacfontes/futebol_2025/blob/main/ifood_abtest_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vkPl-VWZUsYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc964549-5a90-4592-cc12-5f12c53af374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.5.1)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.15.2 (from -r requirements.txt (line 4))\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.10.1 (from -r requirements.txt (line 5))\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Collecting statsmodels==0.14.2 (from -r requirements.txt (line 7))\n",
            "  Downloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting tqdm==4.66.4 (from -r requirements.txt (line 8))\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson==3.9.15 (from -r requirements.txt (line 9))\n",
            "  Downloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.32.3)\n",
            "Collecting pyarrow==15.0.2 (from -r requirements.txt (line 11))\n",
            "  Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.17.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.5.1->-r requirements.txt (line 1)) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels==0.14.2->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 10)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 10)) (2025.4.26)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 12)) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (5.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (4.3.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 12)) (0.2.13)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, orjson, numpy, jedi, scipy, pyarrow, statsmodels, matplotlib\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.10.18\n",
            "    Uninstalling orjson-3.10.18:\n",
            "      Successfully uninstalled orjson-3.10.18\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.14.4\n",
            "    Uninstalling statsmodels-0.14.4:\n",
            "      Successfully uninstalled statsmodels-0.14.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.7.3 requires tqdm>=4.67, but you have tqdm 4.66.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jedi-0.19.2 matplotlib-3.10.1 numpy-1.26.4 orjson-3.9.15 pyarrow-15.0.2 scipy-1.15.2 statsmodels-0.14.2 tqdm-4.66.4\n"
          ]
        }
      ],
      "source": [
        "# Instalação de Pacotes\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 2. Configuração do Ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ],
      "metadata": {
        "id": "3f23BJeXVZLQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Inicialização da SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"iFood AB Test - Ingestão\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "GwUe6xYuc9tC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Download dos Arquivos\n",
        "import requests\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "nLkxxARjc_tG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs dos arquivos\n",
        "data_urls = {\n",
        "    \"order.json.gz\": \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/order.json.gz\",\n",
        "    \"consumer.csv.gz\": \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/consumer.csv.gz\",\n",
        "    \"restaurant.csv.gz\": \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/restaurant.csv.gz\",\n",
        "    \"ab_test_ref.tar.gz\": \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/ab_test_ref.tar.gz\"\n",
        "}\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "for name, url in data_urls.items():\n",
        "    path = f\"data/{name}\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"🔽 Baixando: {name}\")\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(path, \"wb\") as f:\n",
        "            for chunk in tqdm(r.iter_content(chunk_size=8192), desc=f\"⬇️ {name}\"):\n",
        "                f.write(chunk)\n",
        "        print(f\"✅ Download concluído: {name}\")\n",
        "    else:\n",
        "        print(f\"✅ Já existe: {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMEkwLYidEeq",
        "outputId": "ee6c7bf6-bdd4-44f1-ac72-37003f0deeff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Já existe: order.json.gz\n",
            "✅ Já existe: consumer.csv.gz\n",
            "✅ Já existe: restaurant.csv.gz\n",
            "✅ Já existe: ab_test_ref.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Inspeção e extração do arquivo TAR\n",
        "import tarfile\n",
        "with tarfile.open(\"data/ab_test_ref.tar.gz\", \"r:gz\") as tar:\n",
        "    members = tar.getnames()\n",
        "    print(f\"📦 Arquivos dentro de data/ab_test_ref.tar.gz:\")\n",
        "    for name in members:\n",
        "        print(\"—\", name)\n",
        "    # Ignora arquivos ocultos (ex: criados por sistemas macOS)\n",
        "    safe_members = [m for m in members if not m.startswith(\"._\")]\n",
        "    tar.extractall(path=\"data\", members=[m for m in tar if m.name in safe_members])\n",
        "    print(\"✅ Extração concluída\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NAtAnQOdZh3",
        "outputId": "8ab7e35b-dc02-4c70-c534-d15125567f97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Arquivos dentro de data/ab_test_ref.tar.gz:\n",
            "— ._ab_test_ref.csv\n",
            "— ab_test_ref.csv\n",
            "✅ Extração concluída\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Leitura com PySpark\n",
        "# Acompanhando o carregamento\n",
        "import time\n",
        "start = time.time()\n",
        "df_orders = spark.read.json(\"data/order.json.gz\")\n",
        "print(f\"⏱️ Tempo para carregar orders: {round(time.time() - start, 2)}s\")\n",
        "start = time.time()\n",
        "df_users = spark.read.option(\"header\", True).csv(\"data/consumer.csv.gz\")\n",
        "print(f\"⏱️ Tempo para carregar users: {round(time.time() - start, 2)}s\")\n",
        "start = time.time()\n",
        "df_restaurants = spark.read.option(\"header\", True).csv(\"data/restaurant.csv.gz\")\n",
        "print(f\"⏱️ Tempo para carregar restaurants: {round(time.time() - start, 2)}s\")\n",
        "start = time.time()\n",
        "df_abtest = spark.read.option(\"header\", True).csv(\"data/ab_test_ref.csv\")\n",
        "print(f\"⏱️ Tempo para carregar abtest: {round(time.time() - start, 2)}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTC80yTrflx2",
        "outputId": "65b15aa8-42ba-496f-de09-5ecae1a94818"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Tempo para carregar orders: 137.14s\n",
            "⏱️ Tempo para carregar users: 1.57s\n",
            "⏱️ Tempo para carregar restaurants: 0.79s\n",
            "⏱️ Tempo para carregar abtest: 0.71s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe uma amostra de cada DataFrame\n",
        "print(\"Amostra de Pedidos:\"); df_orders.show(3)\n",
        "print(\"Amostra de Usuários:\"); df_users.show(3)\n",
        "print(\"Amostra de Restaurantes:\"); df_restaurants.show(3)\n",
        "print(\"Amostra de Teste A/B:\"); df_abtest.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GAgoc-chwNT",
        "outputId": "4a5c405c-9e3b-4fb0-8bd7-6c976f6786a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostra de Pedidos:\n",
            "+-----------+--------------------+-------------+---------------------+------------------------+-------------------------+----------------------------+-------------------------+--------------------------+----------------------+-------------------------+--------------------+--------------------+-----------------+------------------+-----------------+--------------------+--------------------+---------------+--------------------+------------------+---------------+\n",
            "|        cpf|         customer_id|customer_name|delivery_address_city|delivery_address_country|delivery_address_district|delivery_address_external_id|delivery_address_latitude|delivery_address_longitude|delivery_address_state|delivery_address_zip_code|               items|         merchant_id|merchant_latitude|merchant_longitude|merchant_timezone|    order_created_at|            order_id|order_scheduled|order_scheduled_date|order_total_amount|origin_platform|\n",
            "+-----------+--------------------+-------------+---------------------+------------------------+-------------------------+----------------------------+-------------------------+--------------------------+----------------------+-------------------------+--------------------+--------------------+-----------------+------------------+-----------------+--------------------+--------------------+---------------+--------------------+------------------+---------------+\n",
            "|80532101763|7ba88a68bb2a3504c...|      GUSTAVO|               FRANCA|                      BR|         JARDIM ESPRAIADO|                     6736655|                   -47.39|                    -20.55|                    SP|                    14403|[{\"name\": \"Parmeg...|a992a079a651e699d...|           -47.39|            -20.55|America/Sao_Paulo|2019-01-17T22:50:...|33e0612d62e5eb42a...|          false|                NULL|              46.0|        ANDROID|\n",
            "|43352103961|078acecdcf7fa89d3...|     MICHELLE|               SANTOS|                      BR|             CAMPO GRANDE|                     8759216|                   -46.34|                    -23.96|                    SP|                    11070|[{\"name\": \"Filé M...|5152f28ee0518b880...|           -46.34|            -23.96|America/Sao_Paulo|2019-01-17T17:51:...|148c4353a2952f3fe...|          false|                NULL|             104.5|        ANDROID|\n",
            "|38650991217|0e38a3237b5946e8a...|       VICTOR|            GUARULHOS|                      BR|             JARDIM ROSSI|                     8765930|                   -46.53|                    -23.44|                    SP|                    71304|[{\"name\": \"GRANDE...|b6096419455c35d06...|           -46.53|            -23.44|America/Sao_Paulo|2019-01-17T22:53:...|c37e495a91b498bb7...|          false|                NULL|              35.0|            IOS|\n",
            "+-----------+--------------------+-------------+---------------------+------------------------+-------------------------+----------------------------+-------------------------+--------------------------+----------------------+-------------------------+--------------------+--------------------+-----------------+------------------+-----------------+--------------------+--------------------+---------------+--------------------+------------------+---------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Amostra de Usuários:\n",
            "+--------------------+--------+--------------------+------+-------------+-------------------+---------------------+\n",
            "|         customer_id|language|          created_at|active|customer_name|customer_phone_area|customer_phone_number|\n",
            "+--------------------+--------+--------------------+------+-------------+-------------------+---------------------+\n",
            "|e8cc60860e09c0bb1...|   pt-br|2018-04-05T14:49:...|  true|         NUNO|                 46|            816135924|\n",
            "|a2834a38a9876cf74...|   pt-br|2018-01-14T21:40:...|  true|     ADRIELLY|                 59|            231330577|\n",
            "|41e1051728eba1334...|   pt-br|2018-01-07T03:47:...|  true|        PAULA|                 62|            347597883|\n",
            "+--------------------+--------+--------------------+------+-------------+-------------------+---------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Amostra de Restaurantes:\n",
            "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
            "|                  id|          created_at|enabled|price_range|average_ticket|takeout_time|delivery_time|minimum_order_value|merchant_zip_code| merchant_city|merchant_state|merchant_country|\n",
            "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
            "|d19ff6fca6288939b...|2017-01-23T12:52:...|  false|          3|          60.0|           0|           50|               30.0|            14025|RIBEIRAO PRETO|            SP|              BR|\n",
            "|631df0985fdbbaf27...|2017-01-20T13:14:...|   true|          3|          60.0|           0|            0|               30.0|            50180|     SAO PAULO|            SP|              BR|\n",
            "|135c5c4ae4c1ec1fd...|2017-01-23T12:46:...|   true|          5|         100.0|           0|           45|               10.0|            23090|RIO DE JANEIRO|            RJ|              BR|\n",
            "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Amostra de Teste A/B:\n",
            "+--------------------+---------+\n",
            "|         customer_id|is_target|\n",
            "+--------------------+---------+\n",
            "|755e1fa18f25caec5...|   target|\n",
            "|b821aa8372b8e5b82...|  control|\n",
            "|d425d6ee4c9d4e211...|  control|\n",
            "+--------------------+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Pré-processamento básico\n",
        "# Remove registros inválidos de pedidos sem cliente, ID de pedido ou valor total — essenciais para análise.\n",
        "df_orders = df_orders.dropna(subset=[\"customer_id\", \"order_id\", \"order_total_amount\"])\n",
        "df_abtest = df_abtest.filter(df_abtest.is_target.isNotNull())\n"
      ],
      "metadata": {
        "id": "Pw9ghS0ojnKk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Join dos dados principais\n",
        "df_joined = df_orders.join(df_abtest, on=\"customer_id\", how=\"inner\")"
      ],
      "metadata": {
        "id": "MiJ5Juv_lwQp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Exporta amostra para Pandas para análise inicial (reduzido para 50.000 registros)\n",
        "# Reinicie o ambiente e reinstale numpy se encontrar erro de incompatibilidade (dtype size)\n",
        "# !pip install --force-reinstall numpy==1.26.4 --no-cache-dir && os.kill(os.getpid(), 9)\n",
        "\n",
        "try:\n",
        "    start = time.time()\n",
        "    sample_df = df_joined.limit(50000).toPandas()\n",
        "    print(f\"⏱️ Tempo para converter para Pandas: {round(time.time() - start, 2)}s\")\n",
        "except ValueError as e:\n",
        "    print(\"❌ Erro ao converter para Pandas. Pode ser uma incompatibilidade do NumPy.\\n\", str(e))\n",
        "    raise\n",
        "\n",
        "os.makedirs(\"trusted_data\", exist_ok=True)\n",
        "sample_output_path = \"trusted_data/sample_orders.parquet\"\n",
        "sample_df.to_parquet(sample_output_path, index=False)\n",
        "print(f\"✅ Arquivo de amostra salvo como {sample_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXqMOwY_mR_y",
        "outputId": "452a0df1-62d8-4852-9a93-e49a1bae2406"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Tempo para converter para Pandas: 219.62s\n",
            "✅ Arquivo de amostra salvo como trusted_data/sample_orders.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Salvando os DataFrames completos como .parquet para análises finais\n",
        "output_path_orders = \"trusted_data/processed_orders.parquet\"\n",
        "df_joined.write.mode(\"overwrite\").parquet(output_path_orders)\n",
        "print(f\"✅ Arquivo de pedidos salvo como {output_path_orders}\")\n",
        "\n",
        "output_path_users = \"trusted_data/processed_users.parquet\"\n",
        "df_users.write.mode(\"overwrite\").parquet(output_path_users)\n",
        "print(f\"✅ Arquivo de usuários salvo como {output_path_users}\")\n",
        "\n",
        "output_path_restaurants = \"trusted_data/processed_restaurants.parquet\"\n",
        "df_restaurants.write.mode(\"overwrite\").parquet(output_path_restaurants)\n",
        "print(f\"✅ Arquivo de restaurantes salvo como {output_path_restaurants}\")\n",
        "\n",
        "output_path_abtest = \"trusted_data/processed_abtest.parquet\"\n",
        "df_abtest.write.mode(\"overwrite\").parquet(output_path_abtest)\n",
        "print(f\"✅ Arquivo de teste A/B salvo como {output_path_abtest}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wHWG-uru731",
        "outputId": "355675c9-c5f2-4da6-ff73-76b70811570b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Arquivo de pedidos salvo como trusted_data/processed_orders.parquet\n",
            "✅ Arquivo de usuários salvo como trusted_data/processed_users.parquet\n",
            "✅ Arquivo de restaurantes salvo como trusted_data/processed_restaurants.parquet\n",
            "✅ Arquivo de teste A/B salvo como trusted_data/processed_abtest.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Explode os itens dos pedidos em uma tabela separada\n",
        "from pyspark.sql.functions import explode, from_json, col\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, DoubleType, IntegerType\n",
        "\n",
        "item_schema = ArrayType(StructType([\n",
        "    StructField(\"external_id\", StringType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"price\", DoubleType(), True),\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"total_price\", DoubleType(), True)\n",
        "]))\n",
        "\n",
        "orders_with_items = df_orders.withColumn(\"items_array\", from_json(col(\"items\"), item_schema))\n",
        "\n",
        "df_item_orders = orders_with_items.select(\n",
        "    \"order_id\",\n",
        "    \"customer_id\",\n",
        "    explode(\"items_array\").alias(\"item\")\n",
        ")\n",
        "\n",
        "df_item_orders = df_item_orders.select(\n",
        "    \"order_id\",\n",
        "    \"customer_id\",\n",
        "    \"item.name\",\n",
        "    \"item.price\",\n",
        "    \"item.quantity\",\n",
        "    \"item.total_price\",\n",
        "    \"item.external_id\"\n",
        ")\n",
        "\n",
        "output_path_items = \"trusted_data/processed_item_orders.parquet\"\n",
        "df_item_orders.write.mode(\"overwrite\").parquet(output_path_items)\n",
        "print(f\"✅ Arquivo de itens de pedidos salvo como {output_path_items}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxNqG078vATc",
        "outputId": "d6ebe792-e759-4733-ad5d-36cecbdaa106"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Arquivo de itens de pedidos salvo como trusted_data/processed_item_orders.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AdmtangD6c1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}